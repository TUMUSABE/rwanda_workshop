{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploratory Data Analysis and Regression\n",
    "## Introduction to Data Science\n",
    "### Kigali, Rwanda\n",
    "### July 8th, 2019\n",
    "\n",
    "\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "1. Linear Regression\n",
    "2. Multi-linear and Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a Model?\n",
    "\n",
    "This is a scatter plot of home prices vs square footage of some homes in southern California.\n",
    "\n",
    "<img src=\"fig/fig32.jpg\" style=\"height:350px;\">\n",
    "\n",
    "Can you see any patterns or trends?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a Model?\n",
    "\n",
    "We see that as **square footage** increases, so does **price**. \n",
    "\n",
    "<img src=\"fig/fig32.jpg\" style=\"height:350px;\">\n",
    "\n",
    "But what is a precise, mathematical description of this relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a Model?\n",
    "\n",
    "Building a model to capture a hypothesized relationship means we predict the value of one group of attributes using another group. \n",
    "\n",
    "This prediction problem is called ***regression***, the attribute we are trying to predict (e.g.price) is called the ***outcome*** or the ***target***, denoted by $y$. \n",
    "\n",
    "The group of attributes (e.g. square footage) we use to make the prediction is called the ***covariates***, denoted by $x$.\n",
    "\n",
    "A ***regression model*** is a mathematical function, $f(x)$, that predicts the target. We denote our prediction by $\\hat{y} = f(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a Model?\n",
    "\n",
    "We conjectured that the model for this data is a line: $\\hat{y} = f(x) = w_1x + w_0$.\n",
    "\n",
    "<img src=\"fig/fig33.jpg\" style=\"height:350px;\">\n",
    "\n",
    "But which line fits the data best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Notion of Error\n",
    "\n",
    "An ***absolute residual*** is the absolute difference between the actual price of a home and the price predicted by the line for a given square footage:\n",
    "$$\n",
    "\\mathtt{Residual}_i = y_i - \\hat{y}_i\n",
    "$$\n",
    "\n",
    "<img src=\"fig/fig34.jpg\" style=\"height:350px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we quantify the overall error?\n",
    "\n",
    "1. **(Max absolute deviation)** Count only the biggest \"error\"\n",
    "$$\n",
    "\\max_i |y_i - \\hat{y}_i| \n",
    "$$\n",
    "2. **(Sum of absolute deviations)** Add up all the \"errors\"\n",
    "$$\n",
    "\\sum_i |y_i - \\hat{y}_i| \n",
    "$$\n",
    "3. **(Sum of squared errors)** Add up the squares of the \"errors\"\n",
    "$$\n",
    "\\sum_i |y_i - \\hat{y}_i|^2 \n",
    "$$\n",
    "4. **(Mean squared errors)** We can also average the squared \"errors\".\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{i=1}^N |y_i - \\hat{y}_i|^2 \n",
    "$$\n",
    "\n",
    "Again, $y_i$ is the observed target, $\\hat{y}_i$ is the predicted target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Fitting\n",
    "\n",
    "**Question:** What do we mean by choosing \"best\" line, $\\hat{y} = w_1x_1 + w_0$? \n",
    "\n",
    "The ***model fitting*** process:\n",
    "\n",
    "1. *Choose* an overall error metric. This metric is called the ***loss function***:\n",
    "$$\n",
    "\\mathcal{L}(w_0, w_1) = \\frac{1}{N}\\sum_{i=1}^N |y_i - (w_1x_1 + w_0)|^2 \n",
    "$$\n",
    "\n",
    "2. Set up the problem of finding coefficients or ***parameters***, $w_0, w_1$, such that the loss function is **minimized**:\n",
    "$$\n",
    "\\min_{w_0, w_1}\\mathcal{L}(w_0, w_1) = \\min_{w_0, w_1}\\frac{1}{N}\\sum_{i=1}^N |y_i - (w_1x_1 + w_0)|^2 \n",
    "$$\n",
    "\n",
    "3. Choose a method of minimizing the loss function.\n",
    "\n",
    "**Note:** For linear regression, we can minimize $\\mathcal{L}$ analytically. We cannot do this for every model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression in `sklearn`\n",
    "\n",
    "```python\n",
    "# import the LinearRegression model from the sklearn library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# make an instance of the linear regression model\n",
    "regression = LinearRegression()\n",
    "\n",
    "# find the coefficients for the line that minimizes mean squared error\n",
    "regression.fit(x_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "After fitting the model (finding coefficients that minimize the loss function), we need to **check the error of the model**. Why?\n",
    "<img src=\"fig/fig36.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Evaluation on Train and Test\n",
    "\n",
    "Rather than computing the mean square error (which depends on units), we often compute the ***coefficient of determination*** or the $R^2$ of our model. \n",
    "\n",
    "This is a number between 0 and 1, indicating the percentage of the data variation captured by our model.\n",
    "\n",
    "<img src=\"fig/fig37.jpg\" style=\"height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where Does Test Data Come From?\n",
    "\n",
    "Typically, data is collected once. New data for testing your model maybe expensive or impossible to collect. \n",
    "\n",
    "In practice, we split our data into two: one we use for training our models, and one we set aside for **final testing** after a model has been chosen.\n",
    "\n",
    "```python\n",
    "# Import function for splitting data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split our data into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Interpretation\n",
    "\n",
    "In addition to evaluating our model on training and testing data, we must also examine the coefficients themselves. Why?\n",
    "\n",
    "<img src=\"fig/fig35.jpg\" style=\"height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocessing: Scaling the Data\n",
    "\n",
    "If we are fitting a linear regression model \n",
    "$$\\hat{y} = w_0 + w_1x,$$ \n",
    "the units (and hence the scale) of $x$ will affect the magnitude of the coefficients $w_0, w_1$.\n",
    "\n",
    "To prevent learning non-sensical coefficients, we often scale the data to a fixed range before fitting our model, this is called ***preprocessing***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing in `sklearn`\n",
    "\n",
    "```python\n",
    "# import the model for scaling data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# make an instance of the scaler\n",
    "scaler = MinMaxScaler(0, 1)\n",
    "scaler.fit(x_train)\n",
    "# scale training data\n",
    "x_train = scaler.transform(x_train)\n",
    "# scale testing data\n",
    "x_test = scaler.transform(x_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression with Multiple Covariates\n",
    "\n",
    "It’s unreasonable for price of a home to depend on square footage alone. In reality, price most likely depends on some combination of square footage, $x_1$, number of bedrooms, $x_2$, and the number of bathrooms, $x_3$.\n",
    "\n",
    "$$\n",
    "\\hat{y} = f_W(x_1, x_2, x_3) = w_0 + w_1x_1 + w_2x_2 + x_3x_3\n",
    "$$\n",
    "\n",
    "<img src=\"fig/fig38.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fitting Linear Regression Models with Multiple Covariates\n",
    "\n",
    "Again, fitting the model means finding coefficients $W = [w_0, w_1, w_2, w_3]$ to minimize mean squared error:\n",
    "\n",
    "$$\n",
    "\\min_{W}\\mathcal{L}(W) = \\min_{W}\\frac{1}{N}\\sum_{i=1}^N |y_i - f_W(x)|^2 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Models for Regression\n",
    "\n",
    "You might notice that our linear models (univariate and multivariate) don’t seem to fit the housing data very well.\n",
    "\n",
    "Maybe this is because the underlying relationship between price and square footage, $x$, isn’t linear. Perhaps the model we want is the polynomial:\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(x) = w_0 + w_1 x + w_2 x^2\n",
    "$$\n",
    "\n",
    "Does this mean that we need to define a new model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression as Linear Regression\n",
    "\n",
    "While the function $f(x) = w_0 + w_1 x + w_2 x^2$ is degree 2 in the input $x$, it is **linear** in the input $[x, x^2]$. That is, if we transformed the data into $[x_i, x_i^2]$ for each $x_i$, then we can fit a linear regression model:\n",
    "$$\n",
    "g(x, x^2) = w_0 + w_1 x + w_2 x^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fitting a Polynomial Regression Model\n",
    "\n",
    "1. transform the training data into polynomial features: $x \\to [x_i, x_i^2]$\n",
    "<img src=\"fig/fig40.jpg\" style=\"height:200px;\">\n",
    "2. fit a linear regression model:\n",
    "$$\n",
    "g(x, x^2) = w_0 + w_1 x + w_2 x^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression in `sklearn`\n",
    "\n",
    "```python\n",
    "# import model to transform data into polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# set the polynomial degree\n",
    "degree_of_polynomial = 2\n",
    "# make an instance of the sklearn model for transforming features into polynomial features\n",
    "polynomial_transform = PolynomialFeatures(degree_of_polynomial, include_bias=False)\n",
    "\n",
    "polynomial_transform.fit(x_train)\n",
    "# transform x_train to polynomial x_train\n",
    "x_train_poly = polynomial_transform.transform(x_train)\n",
    "# transform x_test to polynomial x_test\n",
    "x_test_poly = polynomial_transform.transform(x_test)\n",
    "\n",
    "# fit a linear regression model to the polynomial features\n",
    "regression.fit(x_train_poly, y_train)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
